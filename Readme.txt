Описание моделей (Метрика - Brier Score): 
-----------

Просто на средних Brier Score = 0.1

Я разделил выборку на обучающую, валидационную и тестовую ( 80% - train and validation, 20% - test)
k_folds = 4 (для кросс-валидации)

Всего я проработал 8 моделей: 
	- 4 модели без признаков, связанных с тестовыми данными (768 признаков)
	- 4 модели с признаками, связанными с текстовыми данными

Внутри этого разбиения каждая из четырех моделей - Logit with Elastic Net Regularization, отличающиеся
параметром l1_ration (0 [L2 reg.], 0.33, 0.66, 1 [L1 reg.])

Каждую из восьми моделей я обучаю с помощью grid-search:

	* C        : np.geomspace(0.01, 5, 20)
	* k_folds  : 4
	* max_iter : 350
	* penalty  : elasticnet
	* solver   : saga


Результаты: 
-----------

На тестовой выборке с лучшим подбором гиперпараметра С для каждой из восьми моделей: 

1. С текстовыми фичами:
	l1_ratio: 
		 * 0    -> oos_BS = 0.047
		 * 0.33 -> oos_BS = 0.049
		 * 0.66 -> oos_BS = 0.051
		 * 1    -> oos_BS = 0.054 

2. Без текстовых фичей:
	l1_ratio: 
		 * 0    -> oos_BS = 0.037
		 * 0.33 -> oos_BS = 0.035
		 * 0.66 -> oos_BS = 0.035
		 * 1    -> oos_BS = 0.035

Но на in_sample данных результаты схожи
(См. результаты на графиках в файле main_file)

Вопросы:
-----------

1. Может, мне стоит воспользоваться дополнительно моделью PCA, чтобы вместо 768 признаков,
связанных с тестовыми данными, получить несколько десятков топиков ключевых (самых популярных) слов ? 


Необходимо делать дальше:
-----------

Писать текст курсовой 